{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import gzip\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import json\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import balanced_accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "def load_dataset(path: str) -> pd.DataFrame:\n",
    "    return pd.read_csv(path, index_col=False, compression='zip')\n",
    "\n",
    "def clean_dataset(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    new_df = df.copy()\n",
    "    new_df = new_df.rename(columns={'default payment next month': 'default'})\n",
    "    new_df = new_df.drop(columns=['ID'])\n",
    "    new_df = new_df.loc[new_df[\"MARRIAGE\"] != 0]\n",
    "    new_df = new_df.loc[new_df[\"EDUCATION\"] != 0]\n",
    "    new_df[\"EDUCATION\"] = new_df[\"EDUCATION\"].apply(lambda x: x if x < 4 else 4)\n",
    "    return new_df\n",
    "\n",
    "def create_pipeline() -> Pipeline:\n",
    "    cat_features = [\"SEX\", \"EDUCATION\", \"MARRIAGE\"]\n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "            ('cat', OneHotEncoder(handle_unknown='ignore'), cat_features)\n",
    "        ],\n",
    "        remainder='passthrough'\n",
    "    )\n",
    "    return Pipeline(steps=[('preprocessor', preprocessor), ('classifier', RandomForestClassifier(random_state=42))])\n",
    "\n",
    "def create_estimator(pipeline: Pipeline) -> GridSearchCV:\n",
    "    param_grid = {\n",
    "\t    'classifier__n_estimators': [50, 100, 200],\n",
    "\t    'classifier__max_depth': [None, 5, 10, 20],\n",
    "\t    'classifier__min_samples_split': [2, 5, 10],\n",
    "\t    'classifier__min_samples_leaf': [1, 2, 4]\n",
    "    }\n",
    "\n",
    "    return GridSearchCV(\n",
    "        pipeline,\n",
    "        param_grid,\n",
    "        cv=10,\n",
    "        scoring='balanced_accuracy',\n",
    "        n_jobs=-1,\n",
    "        verbose=2,\n",
    "        refit=True\n",
    "    )\n",
    "\n",
    "def save_model(path: str, estimator: GridSearchCV):\n",
    "    with gzip.open(path, 'wb') as f:\n",
    "        pickle.dump(estimator, f)\n",
    "\n",
    "def calculate_precision_metrics(dataset_name: str, y, y_pred) -> dict: \n",
    "    return {\n",
    "        'type': 'metrics',\n",
    "        'dataset': dataset_name,\n",
    "\t    'precision': precision_score(y, y_pred, zero_division=0),\n",
    "\t    'balanced_accuracy': balanced_accuracy_score(y, y_pred),\n",
    "\t    'recall': recall_score(y, y_pred, zero_division=0),\n",
    "\t    'f1_score': f1_score(y, y_pred, zero_division=0)\n",
    "    }\n",
    "\n",
    "def calculate_confusion_metrics(dataset_name: str, y, y_pred) -> dict:\n",
    "    cm = confusion_matrix(y, y_pred)\n",
    "    return {\n",
    "        'type': 'cm_matrix',\n",
    "\t    'dataset': dataset_name,\n",
    "\t    'true_0': {\"predicted_0\": int(cm[0][0]), \"predicted_1\": int(cm[0][1])},\n",
    "\t    'true_1': {\"predicted_0\": int(cm[1][0]), \"predicted_1\": int(cm[1][1])}\n",
    "    }\n",
    "    \n",
    "def main():\n",
    "    path1 = \"../files/input/\"\n",
    "    path2 = \"../files/models/\"\n",
    "\n",
    "    # Paso 1, Carga y limpieza de los datasets.\n",
    "    # Carga de los datasets.\n",
    "    test_df = load_dataset(os.path.join(path1, 'test_data.csv.zip'))\n",
    "    train_df = load_dataset(os.path.join(path1, 'train_data.csv.zip'))\n",
    "\n",
    "    # Limpieza de los datasets.\n",
    "    test_df = clean_dataset(test_df)\n",
    "    train_df = clean_dataset(train_df)\n",
    "\n",
    "    # Paso 2, División de los datasets.\n",
    "    x_test = test_df.drop(columns=['default'])\n",
    "    y_test = test_df['default']\n",
    "\n",
    "    x_train = train_df.drop(columns=['default'])\n",
    "    y_train = train_df['default']\n",
    "\n",
    "    # Paso 3, Creación del pipeline.\n",
    "    pipeline = create_pipeline()\n",
    "\n",
    "    # Paso 4, Optimización de los hiperparametros.\n",
    "    estimator = create_estimator(pipeline)\n",
    "    estimator.fit(x_train, y_train)\n",
    "\n",
    "    # Paso 5, Guardado del modelo\n",
    "    save_model(\n",
    "        os.path.join(path2, 'model.pkl.gz'),\n",
    "        estimator,\n",
    "    )\n",
    "\n",
    "    # Paso 6, Calcular las metricas de precisión\n",
    "    y_test_pred = estimator.predict(x_test)\n",
    "    test_precision_metrics = calculate_precision_metrics(\n",
    "        'test',\n",
    "        y_test,\n",
    "        y_test_pred\n",
    "    )\n",
    "    y_train_pred = estimator.predict(x_train)\n",
    "    train_precision_metrics = calculate_precision_metrics(\n",
    "        'train',\n",
    "        y_train,\n",
    "        y_train_pred\n",
    "    )\n",
    "\n",
    "    # Paso 7, Calcular metricas de confusión\n",
    "    test_confusion_metrics = calculate_confusion_metrics('test', y_test, y_test_pred)\n",
    "    train_confusion_metrics = calculate_confusion_metrics('train', y_train, y_train_pred)\n",
    "\n",
    "    with open('../files/output/metrics.json', 'w') as file:\n",
    "        file.write(json.dumps(train_precision_metrics)+'\\n')\n",
    "        file.write(json.dumps(test_precision_metrics)+'\\n')\n",
    "        file.write(json.dumps(train_confusion_metrics)+'\\n')\n",
    "        file.write(json.dumps(test_confusion_metrics)+'\\n')\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
